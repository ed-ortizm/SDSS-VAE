{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astroML.datasets import sdss_corrected_spectra\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "plt.rc('legend', fontsize='x-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/epyc/users/sportill/specAE/spec64k.npz')\n",
    "rawspec = sdss_corrected_spectra.reconstruct_spectra(data)\n",
    "lam = sdss_corrected_spectra.compute_wavelengths(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match VAE training\n",
    "spec = rawspec / data['norms'][:,None] # normalize spectra with PCA norm\n",
    "meanspec = np.mean(spec, axis=0)\n",
    "nfeat = meanspec.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches VAE training\n",
    "spec_err = data['spec_err'] / data['norms'][:,None]\n",
    "lowspecerr = (data['spec_err'] < 0.25) # some errors ~ 0 or are negative?\n",
    "spec_weig = 1./(spec_err*spec_err + 1./(2e6)) # cap weights\n",
    "spec_mask = data['mask']\n",
    "spec_weig[spec_mask] = 0 # if spectrum masked, act as if err = inf\n",
    "spec_weig[lowspecerr] = 0\n",
    "spec_err[spec_mask] = float('nan')\n",
    "spec_err[lowspecerr] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specclass = data['lineindex_cln']\n",
    "# map lineindex_cln 2,3 to 0 and 4,5,6 to 1,2,3\n",
    "specclass -= 3\n",
    "specclass[specclass == -1] = 0 # set line_index 2 -> 0\n",
    "specclass[specclass < -1] = -1\n",
    "specclass[specclass > 3] = -1\n",
    "specclassnames = ['quiescent galaxy', 'emission-line galaxy', 'narrow-line AGN', 'broad-line AGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_models(tag):\n",
    "    metrics = np.load(tag+'/metrics.npz')\n",
    "    order = np.argsort(metrics['MSE'])\n",
    "    for i in order[0:10]:\n",
    "        m = torch.load(tag+'/%04i.pth' % i)\n",
    "        print('Model %04i MSE %0.3e KLD %0.2e MMD %0.2e lambda %0.2e nhidden %i %i' % (i, metrics['MSE'][i], metrics['KLD'][i], metrics['MMD'][i], m.lambd, m.encd.out_features, m.enc2.out_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('64k_20190612/0057.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.load('64k_20190612/datasplit.npz')\n",
    "valididx = ds['valididx']\n",
    "trainidx = ds['trainidx']\n",
    "\n",
    "allidx = np.concatenate((valididx, trainidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_mjd_fiber = np.column_stack((data['plate'], data['mjd'], data['fiber']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    reconspec, latentmu, latentlv = model(torch.tensor(spec - meanspec, dtype=torch.float32))\n",
    "    reconspec = reconspec.numpy()\n",
    "    latentmu = latentmu.numpy()\n",
    "    latentlv = latentlv.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_PCA = PCA()\n",
    "latent_PCA.fit(latentmu[trainidx])\n",
    "latentmu_PCA = latent_PCA.transform(latentmu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tracks in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmapclass = plt.get_cmap('Accent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.2,7.2))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i <= j:\n",
    "            plt.subplot(6,6,i+j*6+1)\n",
    "            if i == 0 and j != 0:\n",
    "                plt.ylabel('VAE %i' % (j + 1))\n",
    "            if j == 5:\n",
    "                plt.xlabel('VAE %i' % (i + 1))\n",
    "            if i != 0:\n",
    "                plt.yticks([])\n",
    "            else:\n",
    "                plt.yticks([-6,-3,0,3,6])\n",
    "            if j != 5:\n",
    "                plt.xticks([])\n",
    "            else:\n",
    "                plt.xticks([-6,-3,0,3,6])\n",
    "            if i < j:\n",
    "                plt.scatter(latentmu_PCA[allidx,i], latentmu_PCA[allidx,j],s=1,marker='.',c=specclass[allidx], cmap=cmapclass)\n",
    "                \n",
    "            if i == j:\n",
    "                plt.hist([latentmu_PCA[specclass == cln, i] for cln in [3,2,1,0]], stacked=True, \\\n",
    "                         label=specclassnames[::-1], \\\n",
    "                         color=[cmapclass(x) for x in [1., 2/3, 1/3, 0.]])\n",
    "                plt.yticks([])\n",
    "                if i == 0:\n",
    "                    plt.legend(bbox_to_anchor=(1.04, 1), loc='upper left', title='classes')\n",
    "plt.savefig('figures/cornerplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_coords(quantity, percentiles, mask):\n",
    "    coords = np.zeros((len(percentiles)-1, model.ncode))\n",
    "    for i in range(len(percentiles)-1):\n",
    "        thismask = mask & \\\n",
    "            (quantity >= np.percentile(quantity, percentiles[i])) & \\\n",
    "            (quantity < np.percentile(quantity, percentiles[i+1]))\n",
    "        coords[i,:] = np.mean(latentmu_PCA[thismask,:], axis=0)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsSF = track_coords(latentmu_PCA[:,0], [0, 30, 60, 90, 95, 100], (specclass == 0) | (specclass == 1))\n",
    "coordsEM = track_coords(latentmu_PCA[:,2] + latentmu_PCA[:,3], \\\n",
    "                        [99, 99.5, 99.75, 99.9, 100], \\\n",
    "                        specclass > -1)\n",
    "coordsAGN = track_coords(latentmu_PCA[:,4] - latentmu_PCA[:,5], [0, 95, 98, 99, 99.75, 100], specclass >= 2)\n",
    "coordsPSB = track_coords(latentmu_PCA[:,1], [0, 1, 5, 95, 99, 100], (specclass == 0) | (specclass == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_tracks(tracklist, letters, dimx, dimy):\n",
    "#    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    plt.scatter(latentmu_PCA[allidx,dimx], latentmu_PCA[allidx,dimy],s=1,marker='.',c=specclass[allidx], cmap=cmapclass)\n",
    "    for i, coords in enumerate(tracklist):\n",
    "        plt.plot(coords[:,dimx],coords[:,dimy], c='k')\n",
    "        for j in range(coords.shape[0]):\n",
    "            plt.text(coords[j,dimx], coords[j,dimy], letters[i]+'%i' % (j+1), fontsize='xx-small', \\\n",
    "                     bbox={'boxstyle': 'round', 'facecolor': 'white'}, horizontalalignment='center', verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.2, 3.6))\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.subplot(1,2,1)\n",
    "focus_tracks([coordsSF, coordsPSB], ['S', 'P'], 1, 0)\n",
    "plt.ylabel('VAE 1')\n",
    "plt.xlabel('VAE 2')\n",
    "plt.subplot(1,2,2)\n",
    "focus_tracks([coordsSF, coordsEM, coordsAGN], ['S', 'E', 'A'], 4, 0)\n",
    "plt.yticks([])\n",
    "plt.xlabel('VAE 5')\n",
    "plt.savefig('figures/ztracks.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_track(coords, offset=1, ymax=None, letter='', labels=True):\n",
    "    with torch.no_grad():\n",
    "        recon_batch = model.decode(torch.tensor(latent_PCA.inverse_transform(coords), dtype=torch.float32)).numpy() + meanspec\n",
    "        recon_batch /= np.mean(recon_batch, axis=1)[:,None]\n",
    "        cmapseq = plt.get_cmap(\"viridis\")\n",
    "        for i in range(coords.shape[0])[::-1]:\n",
    "            color = cmapseq(i / coords.shape[0])\n",
    "            plt.plot(lam, recon_batch[i] + i*offset, c=color, lw=1)\n",
    "            if labels:\n",
    "                plt.text(lam[-1], recon_batch[i,-1] + i*offset, ' '+letter+'%i' % (i+1), color=color, fontsize='small')\n",
    "        plt.ylim(0,ymax)\n",
    "        if labels:\n",
    "            plt.xlabel('Wavelength (Ã…)')\n",
    "            plt.ylabel('Normalized Flux + Offset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_track(coordsSF, offset=0.5, letter='S', ymax=4)\n",
    "plt.savefig('figures/SFtrack.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_track(coordsEM, offset=0.5, letter='E', ymax=4)\n",
    "plt.savefig('figures/ELtrack.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_track(coordsPSB, offset=0.5, letter='P', ymax=4)\n",
    "plt.savefig('figures/PSBtrack.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_track(coordsAGN, offset=0.5, letter='A', ymax=4.5)\n",
    "plt.savefig('figures/AGNtrack.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.2, 10.8))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "for i in range(6):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    lower = np.percentile(latentmu_PCA[:,i], 1)\n",
    "    upper = np.percentile(latentmu_PCA[:,i], 99)\n",
    "    coords = np.zeros((5, model.ncode)) + np.mean(latentmu_PCA[trainidx], axis=0)\n",
    "    coords[0,i] = np.percentile(latentmu_PCA[:,i], 1)\n",
    "    coords[1,i] = np.percentile(latentmu_PCA[:,i], 16)\n",
    "    coords[2,i] = np.mean(latentmu_PCA[:,i])\n",
    "    coords[3,i] = np.percentile(latentmu_PCA[:,i], 84)\n",
    "    coords[4,i] = np.percentile(latentmu_PCA[:,i], 99)\n",
    "    plot_track(coords, labels=False)\n",
    "    plt.annotate('VAE %i\\n' % (i+1), (7600, 0))\n",
    "    if i == 2:\n",
    "        plt.ylabel('Normalized Flux + Offset')\n",
    "    if i >= 4:\n",
    "        plt.xlabel('Wavelength (Ã…)')\n",
    "plt.savefig('figures/PCAtracks.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npars = [2, 4, 6, 10]\n",
    "models_npars = []\n",
    "models_paths = ['64k_2par_20190707/0068.pth', '64k_4par_20190706/0009.pth', '64k_6par_20190704/0059.pth']\n",
    "for path in models_paths:\n",
    "    modelp = torch.load(path)\n",
    "    modelp.eval()\n",
    "    models_npars.append(modelp)\n",
    "models_npars.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencoderv3 as AE\n",
    "import tensorflow as tf\n",
    "\n",
    "def evalAE(X, method='reconstruct', n_z=2):\n",
    "    graph = tf.Graph()\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        modelAE = AE.Autoencoder()\n",
    "        modelAE.restore('LS_' + str(n_z))\n",
    "        return modelAE.reconstruct(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PCA = PCA(n_components=10)\n",
    "train_PCA.fit(spec[trainidx] - meanspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure spectra are non-negative for NMF\n",
    "spec_non_neg = spec.copy()\n",
    "spec_non_neg[spec_non_neg < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    class_sel = [None, 0, 1, 2, 3]\n",
    "    \n",
    "    MSE_PCA = np.zeros((len(class_sel), len(npars)))\n",
    "    MSE_NMF = np.zeros((len(class_sel), len(npars)))\n",
    "    MSE_VAE = np.zeros((len(class_sel), len(npars)))\n",
    "    MSE_AE = np.zeros((len(class_sel), len(npars)))\n",
    "    \n",
    "    recon_PCA = np.zeros((len(npars), spec[valididx].shape[0], spec[valididx].shape[1]))\n",
    "    recon_VAE = np.zeros((len(npars), spec[valididx].shape[0], spec[valididx].shape[1]))\n",
    "    recon_NMF = np.zeros((len(npars), spec[valididx].shape[0], spec[valididx].shape[1]))\n",
    "    recon_AE = np.zeros((len(npars), spec[valididx].shape[0], spec[valididx].shape[1]))\n",
    "    \n",
    "    specPCA = train_PCA.transform(spec[valididx] - meanspec)\n",
    "    \n",
    "    for i in range(len(npars)):\n",
    "        specPCAtemp = specPCA.copy()\n",
    "        specPCAtemp[:,npars[i]:] = 0\n",
    "        recon_PCA[i,:,:] = train_PCA.inverse_transform(specPCAtemp) + meanspec\n",
    "        \n",
    "        train_NMF = NMF(n_components=npars[i])\n",
    "        train_NMF.fit(spec_non_neg[trainidx])\n",
    "        recon_NMF[i,:,:] = train_NMF.inverse_transform(train_NMF.transform(spec_non_neg[valididx]))\n",
    "        \n",
    "        recon_AE[i,:,:] = evalAE(spec[valididx], method='reconstruct', n_z=npars[i])\n",
    "        \n",
    "        modeli = models_npars[i]\n",
    "        _, mu_batch, _ = modeli(torch.tensor(spec[valididx] - meanspec, dtype=torch.float32)) # keep latent means\n",
    "        recon_VAE[i,:,:] = modeli.decode(mu_batch).numpy() + meanspec\n",
    "        for j, sel in enumerate(class_sel):\n",
    "            if sel is None:\n",
    "                mask = np.full((specclass[valididx].size), True, dtype=np.bool)\n",
    "            else:\n",
    "                mask = (specclass[valididx] == sel)\n",
    "            MSE_PCA[j,i] = np.mean(spec_weig[valididx][mask] * (recon_PCA[i,mask,:] - spec[valididx][mask,:])**2)\n",
    "            MSE_VAE[j,i] = np.mean(spec_weig[valididx][mask] * (recon_VAE[i,mask,:] - spec[valididx][mask,:])**2)\n",
    "            MSE_NMF[j,i] = np.mean(spec_weig[valididx][mask] * (recon_NMF[i,mask,:] - spec[valididx][mask,:])**2)\n",
    "            MSE_AE[j,i] = np.mean(spec_weig[valididx][mask] * (recon_AE[i,mask,:] - spec[valididx][mask,:])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.2, 4.8))\n",
    "gs = fig.add_gridspec(2, 3)\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "for j, sel in enumerate(class_sel):\n",
    "    if sel is not None:\n",
    "        classname = specclassnames[sel]\n",
    "    else:\n",
    "        classname = \"all\"\n",
    "    if j == 0:\n",
    "        ax = fig.add_subplot(gs[:,0])\n",
    "    else:\n",
    "        ax = fig.add_subplot(gs[(j-1)//2,(j-1)%2+1])\n",
    "    ax.plot(npars, MSE_PCA[j,:], 'o-', label='PCA', c=colors[0])\n",
    "    ax.plot(npars, MSE_NMF[j,:], 'o-', label='NMF', c=colors[2])\n",
    "    ax.plot(npars, MSE_AE[j,:], 'o-', label='AE', c=colors[3])\n",
    "    ax.plot(npars, MSE_VAE[j,:], 'o-', label='VAE', c=colors[1])\n",
    "\n",
    "    if j == 0:\n",
    "        ax.legend(loc=(0.65,0.75))\n",
    "        ax.set_ylabel('reconstruction MSE')\n",
    "    if j == 0 or (j-1)//2 == 1:\n",
    "        ax.set_xticks(npars)\n",
    "    if j == 3:\n",
    "        ax.set_xlabel('number of parameters')\n",
    "    ax.text(0.95,0.9 + (0.05)*(j==0),classname,transform=ax.transAxes,horizontalalignment='right')\n",
    "fig.subplots_adjust(hspace=0)\n",
    "plt.savefig('figures/recon.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom in on some reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoomin(specidx, wavelengths, npix=20, tag=''):\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    thisspec = spec[valididx[specidx], :].copy()\n",
    "    thisspec[spec_mask[valididx[specidx]]] = float('nan')\n",
    "    #specweig = spec_weig[valididx[specidx]]\n",
    "    specstd = spec_err[valididx[specidx]]\n",
    "    \n",
    "    thisPCA = recon_PCA[:,specidx,:].copy()\n",
    "    \n",
    "    thisVAE = recon_VAE[:,specidx,:].copy()    \n",
    "    \n",
    "    print('spectrum', plate_mjd_fiber[valididx[specidx]])\n",
    "    print('median SNR overall', np.nanmedian(thisspec / specstd))\n",
    "    for wavelength in wavelengths:\n",
    "        k = np.where(lam > wavelength)[0][0]\n",
    "        ylim_l = np.nanmin(thisspec[k-npix:k+npix]) *.9\n",
    "        ylim_u = np.nanmax(thisspec[k-npix:k+npix]) *1.1\n",
    "        \n",
    "        ylim_resid = max(np.nanmax(np.abs(thisPCA[:,k-npix:k+npix] - thisspec[k-npix:k+npix])),\n",
    "                         np.nanmax(np.abs(thisVAE[:,k-npix:k+npix] - thisspec[k-npix:k+npix]))) * 1.1\n",
    "        \n",
    "        fig, axes = plt.subplots(3, len(npars), sharex=True, sharey='row',figsize=(7.2,5.4))\n",
    "        fig.subplots_adjust(hspace=0, wspace=0)\n",
    "        for i, j in enumerate(npars):\n",
    "            ax = axes[0, i]\n",
    "            ax.plot(lam[k-npix:k+npix], thisspec[k-npix:k+npix], 'k', label='data')\n",
    "            ax.plot(lam[k-npix:k+npix], thisPCA[i,k-npix:k+npix], c=colors[0], label='PCA recon')\n",
    "            ax.set_title('%i parameters' % (j))\n",
    "            if i == 0:\n",
    "                ax.legend(handlelength=1, fontsize='xx-small')\n",
    "            ax.set_ylim(ylim_l, ylim_u)\n",
    "            ax = axes[1, i]\n",
    "            ax.plot(lam[k-npix:k+npix], thisspec[k-npix:k+npix], 'k', label='data')\n",
    "            ax.plot(lam[k-npix:k+npix], thisVAE[i,k-npix:k+npix], c=colors[1], label='VAE recon')\n",
    "\n",
    "            if i == 0:\n",
    "                ax.legend(handlelength=1, fontsize='xx-small')\n",
    "                ax.set_ylabel('Flux (arbitrary units)')\n",
    "            ax.set_ylim(ylim_l, ylim_u)\n",
    "            ax = axes[2, i]\n",
    "            \n",
    "            ax.fill_between(lam[k-npix:k+npix], -specstd[k-npix:k+npix], specstd[k-npix:k+npix], facecolor='grey', label='noise')\n",
    "            ax.plot(lam[k-npix:k+npix], thisPCA[i,k-npix:k+npix] - thisspec[k-npix:k+npix], c=colors[0], label='PCA resid')\n",
    "            ax.plot(lam[k-npix:k+npix], thisVAE[i,k-npix:k+npix] - thisspec[k-npix:k+npix], c=colors[1], label='VAE resid')\n",
    "            ax.set_ylim(-ylim_resid, ylim_resid)\n",
    "            if i == 0:\n",
    "                ax.legend(handlelength=1, fontsize='xx-small')\n",
    "            ax.set_xlabel('Wavelength (Ã…)')\n",
    "        print('median SNR in window', np.nanmedian(thisspec[k-npix:k+npix] / specstd[k-npix:k+npix]))\n",
    "        plt.savefig('figures/'+tag+('_%i' % (wavelength))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomin(12, [4863, 6565], npix=30, tag='BL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zoomin(2670, [3727, 6565], tag='EL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zoomin(6884, [5896, 6565], tag='hiSNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zoomin(7083, [5896, 6565], tag='loSNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor()\n",
    "lof.fit(latentmu_PCA)\n",
    "outidx = np.argsort(lof.negative_outlier_factor_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    j = outidx[i]\n",
    "    print('%i, %i, %i' % (plate_mjd_fiber[j,0], plate_mjd_fiber[j,1], plate_mjd_fiber[j,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    j = outidx[i]\n",
    "    print('O%i & %i & %i & %i \\\\\\\\' % (i+1, plate_mjd_fiber[j,0], plate_mjd_fiber[j,1], plate_mjd_fiber[j,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outliers(subsel, offset=3):\n",
    "    specout = spec[outidx[subsel]].copy()\n",
    "    weigout = spec_weig[outidx[subsel]]\n",
    "\n",
    "    specout /= np.mean(np.abs(specout), axis=1)[:,None]\n",
    "    specoutfil = specout.copy()\n",
    "    specoutfil[weigout == 0] = float('nan')\n",
    "\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    for i in range(len(subsel)):\n",
    "        plt.plot(lam, specout[i] + offset*i, zorder=-i-0.01, c=colors[subsel[i]], alpha=0.5)\n",
    "        plt.plot(lam, specoutfil[i] + offset*i, zorder=-i, c=colors[subsel[i]])\n",
    "        plt.text(lam[-1], specout[i,-1] + i*offset, 'O%i' % (subsel[i]+1), color=colors[subsel[i]], fontsize='small')\n",
    "    plt.xlim((3250,8800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.2,4.5), dpi=300)\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylabel('Normalized Flux + Offset')\n",
    "plt.yticks([])\n",
    "plt.xlabel('Wavelength (Ã…)')\n",
    "plot_outliers(range(0,5))\n",
    "plt.subplot(1,2,2)\n",
    "plot_outliers(range(5,10))\n",
    "plt.yticks([])\n",
    "plt.xlabel('Wavelength (Ã…)')\n",
    "plt.savefig('figures/outliers.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity to Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_noise = 10000\n",
    "imax = 6884\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    noise_lvls = 10**(np.linspace(-3.5, -2, 10))\n",
    "    SNRs = np.nanmedian((spec[valididx[imax]])[:,None] / np.sqrt(spec_err[valididx[imax]][:,None]**2 + noise_lvls[None,:]**2), axis=0)    \n",
    "    var_encoding = np.zeros((model.ncode, len(noise_lvls)))\n",
    "    med_encodvar = np.zeros((model.ncode, len(noise_lvls)))\n",
    "    bias_encoding = np.zeros((model.ncode, len(noise_lvls)))\n",
    "    for i, noise in enumerate(noise_lvls):\n",
    "        spec_noise_t = torch.tensor(spec[valididx[imax]][None,:] - meanspec + noise * np.random.normal(size=(n_noise, nfeat)), dtype=torch.float32)\n",
    "        recon_batch_noise, mu_noise, logvar_noise = model(spec_noise_t)\n",
    "        var_encoding[:, i] = np.var(mu_noise.numpy(), axis=0)\n",
    "        bias_encoding[:, i] = np.mean(mu_noise.numpy(), axis=0) - latentmu[valididx[imax]]\n",
    "        med_encodvar[:, i] = np.median(logvar_noise.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2,4.5))\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "dimbylv = np.argsort(np.median(latentlv, axis=0))\n",
    "for j in range(6):\n",
    "    i = dimbylv[j]\n",
    "    label1, label2 = None, None\n",
    "    #if j == 0:\n",
    "    #    label1, label2 = 'variance of latent means', 'latent variance'\n",
    "    #plt.loglog(SNRs, var_encoding[i,:] / np.exp(latentlv[valididx[imax],i]), c='k', label=label1)\n",
    "    #plt.loglog(SNRs, np.exp(med_encodvar[i,:]) / np.exp(latentlv[valididx[imax],i]), c=colors[1], label=label2)\n",
    "    plt.loglog(SNRs, var_encoding[i,:] / np.exp(med_encodvar[i,:]), c=colors[1])\n",
    "plt.ylabel('variance of latent means / latent variance')\n",
    "plt.axhline(1, c='k', ls='--')\n",
    "plt.xlabel('spectrum pixel S/N')\n",
    "plt.savefig('figures/noise_zvariance.pdf')\n",
    "plt.text(3.5, 1.1, 'uncertainty in latent space underestimated')\n",
    "plt.text(3.5, 0.9, 'uncertainty in latent space overestimated', verticalalignment='top')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(7.2,4.5))\n",
    "for j in range(6):\n",
    "    i = dimbylv[j]\n",
    "    std = np.sqrt(np.exp(med_encodvar[i,:]))\n",
    "    plt.plot(SNRs, bias_encoding[i,:] / np.exp(0.5*med_encodvar[i,:]), c=colors[1])\n",
    "plt.axhline(1, ls='--', c='k')\n",
    "plt.axhline(-1, ls='--', c='k')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('spectrum pixel S/N')\n",
    "plt.ylabel('bias of latent mean / sqrt(latent variance)')\n",
    "plt.savefig('figures/noise_zbias.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stephen's pytorch/tensorflow",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
